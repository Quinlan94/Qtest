#include "mywindow.h"
#include <QDebug>
#include <iostream>
//#include <gl/glut.h>

#define POINT_SELECTED_R 0
#define POINT_SELECTED_G 1
#define POINT_SELECTED_B 0
#define IMAGE_R 1
#define IMAGE_G 0.1
#define IMAGE_B 0
#define IMAGE_A 0.6
#define IMAGE_SELECTED_R 1
#define IMAGE_SELECTED_G 0
#define IMAGE_SELECTED_B 1
#define IMAGE_SELECTED_A 0.6
#define SELECTION_BUFFER_IMAGE 0
#define SELECTION_BUFFER_POINT 1

#define GRID_RGBA 0.2, 0.2, 0.2, 1
#define X_AXIS_RGBA 0.9, 0, 0, 0.5
#define Y_AXIS_RGBA 0, 0.9, 0, 0.5
#define Z_AXIS_RGBA 0, 0, 0.9, 0.5

inline size_t RGBToIndex(const uint8_t r, const uint8_t g, const uint8_t b) {
  return static_cast<size_t>(r) + static_cast<size_t>(g) * 256 +
         static_cast<size_t>(b) * 65536;
}

// Derive color from unique index, generated by `RGBToIndex`.
inline void IndexToRGB(const size_t index, float& r, float& g, float& b) {
  r = ((index & 0x000000FF) >> 0) / 255.0f;
  g = ((index & 0x0000FF00) >> 8) / 255.0f;
  b = ((index & 0x00FF0000) >> 16) / 255.0f;
}

void FrameBufferToQImage(QImage& image) {
  if (QSysInfo::ByteOrder == QSysInfo::BigEndian) {
    uint* p = (uint*)image.bits();
    uint* end = p + image.width() * image.height();
    while (p < end) {
      uint a = *p << 24;
      *p = (*p >> 8) | a;
      p++;
    }
  } else {
    for (int y = 0; y < image.height(); y++) {
      uint* q = (uint*)image.scanLine(y);
      for (int x = 0; x < image.width(); ++x) {
        const uint pixel = *q;
        *q = ((pixel << 16) & 0xff0000) | ((pixel >> 16) & 0xff) |
             (pixel & 0xff00ff00);
        q++;
      }
    }
  }
  image = image.mirrored();
}

/*
void BuildImageModel(const Image& image, const Camera& camera,
                     const float image_size, const float r, const float g,
                     const float b, const float a, LinePainter::Data& line1,
                     LinePainter::Data& line2, LinePainter::Data& line3,
                     LinePainter::Data& line4, LinePainter::Data& line5,
                     LinePainter::Data& line6, LinePainter::Data& line7,
                     LinePainter::Data& line8, TrianglePainter::Data& triangle1,
                     TrianglePainter::Data& triangle2) {
  // Generate camera dimensions in OpenGL (world) coordinate space
  const float image_width = image_size * camera.Width() / 1024.0f;
  const float image_height =
      image_width * static_cast<float>(camera.Height()) / camera.Width();
  const float image_extent = std::max(image_width, image_height);
  const float camera_extent = std::max(camera.Width(), camera.Height());
  const float camera_extent_world =
      static_cast<float>(camera.ImageToWorldThreshold(camera_extent));
  const float focal_length = 2.0f * image_extent / camera_extent_world;

  const Eigen::Matrix<float, 3, 4> inv_proj_matrix =
      image.InverseProjectionMatrix().cast<float>();

  // Projection center, top-left, top-right, bottom-right, bottom-left corners

  const Eigen::Vector3f pc = inv_proj_matrix.rightCols<1>();
  const Eigen::Vector3f tl =
      inv_proj_matrix *
      Eigen::Vector4f(-image_width, image_height, focal_length, 1);
  const Eigen::Vector3f tr =
      inv_proj_matrix *
      Eigen::Vector4f(image_width, image_height, focal_length, 1);
  const Eigen::Vector3f br =
      inv_proj_matrix *
      Eigen::Vector4f(image_width, -image_height, focal_length, 1);
  const Eigen::Vector3f bl =
      inv_proj_matrix *
      Eigen::Vector4f(-image_width, -image_height, focal_length, 1);

  // Lines from sensor corners to projection center

  line1.point1 = PointPainter::Data(pc(0), pc(1), pc(2), 0.8f * r, g, b, 1);
  line1.point2 = PointPainter::Data(tl(0), tl(1), tl(2), 0.8f * r, g, b, 1);

  line2.point1 = PointPainter::Data(pc(0), pc(1), pc(2), 0.8f * r, g, b, 1);
  line2.point2 = PointPainter::Data(tr(0), tr(1), tr(2), 0.8f * r, g, b, 1);

  line3.point1 = PointPainter::Data(pc(0), pc(1), pc(2), 0.8f * r, g, b, 1);
  line3.point2 = PointPainter::Data(br(0), br(1), br(2), 0.8f * r, g, b, 1);

  line4.point1 = PointPainter::Data(pc(0), pc(1), pc(2), 0.8f * r, g, b, 1);
  line4.point2 = PointPainter::Data(bl(0), bl(1), bl(2), 0.8f * r, g, b, 1);

  line5.point1 = PointPainter::Data(tl(0), tl(1), tl(2), 0.8f * r, g, b, 1);
  line5.point2 = PointPainter::Data(tr(0), tr(1), tr(2), 0.8f * r, g, b, 1);

  line6.point1 = PointPainter::Data(tr(0), tr(1), tr(2), 0.8f * r, g, b, 1);
  line6.point2 = PointPainter::Data(br(0), br(1), br(2), 0.8f * r, g, b, 1);

  line7.point1 = PointPainter::Data(br(0), br(1), br(2), 0.8f * r, g, b, 1);
  line7.point2 = PointPainter::Data(bl(0), bl(1), bl(2), 0.8f * r, g, b, 1);

  line8.point1 = PointPainter::Data(bl(0), bl(1), bl(2), 0.8f * r, g, b, 1);
  line8.point2 = PointPainter::Data(tl(0), tl(1), tl(2), 0.8f * r, g, b, 1);

  // Sensor rectangle

  triangle1.point1 = PointPainter::Data(tl(0), tl(1), tl(2), r, g, b, a);
  triangle1.point2 = PointPainter::Data(tr(0), tr(1), tr(2), r, g, b, a);
  triangle1.point3 = PointPainter::Data(bl(0), bl(1), bl(2), r, g, b, a);

  triangle2.point1 = PointPainter::Data(bl(0), bl(1), bl(2), r, g, b, a);
  triangle2.point2 = PointPainter::Data(tr(0), tr(1), tr(2), r, g, b, a);
  triangle2.point3 = PointPainter::Data(br(0), br(1), br(2), r, g, b, a);
}
*/





mywindow::mywindow(QWidget *parent, QScreen *screen)
    : QWindow(screen),
    focus_distance_(kInitFocusDistance),
    mouse_is_pressed_(false),
//    selected_image_id_(kInvalidImageId),
//    selected_point3D_id_(kInvalidPoint3DId),
    coordinate_grid_enabled_(true),
    near_plane_(kInitNearPlane)
{
    //setGeometry();
    bg_color_[0] = 1.0f;
    bg_color_[1] = 1.0f;
    bg_color_[2] = 1.0f;
    //texture = 0;
    //setFlags(Qt::Widget);
    SetupGL();
    ResizeGL();

}

void mywindow::SetupGL()
{
     setSurfaceType(OpenGLSurface);//将window的表面显示为OpenGL

      QSurfaceFormat format;
      format.setDepthBufferSize(24);
      format.setMajorVersion(3);
      format.setMinorVersion(2);
      format.setSamples(4);
      format.setProfile(QSurfaceFormat::CoreProfile);
    #ifdef DEBUG
      format.setOption(QSurfaceFormat::DebugContext);
    #endif

      setFormat(format);
      create();//创建一个window，前面已经设置为OpenGL了

      // Create an OpenGL context
      context_ = new QOpenGLContext(this);
      context_->setFormat(format);
      context_->create();
      //CHECK(context_->create());

      InitializeGL();
      InitializePainters();

      connect(this, &QWindow::widthChanged, this, &mywindow::ResizeGL);//这步骤必须要，不然视图位置不对
      connect(this, &QWindow::heightChanged, this, &mywindow::ResizeGL);

}

void mywindow::InitializeGL()
{
     context_->makeCurrent(this);
     InitializeSettings();
     InitializeView();
     initTextures();
}

void mywindow::ResizeGL()
{
//    qDebug()<<width();
//    qDebug()<<height();
     context_->makeCurrent(this);
     glViewport(0, 0, width(), height());
     ComposeProjectionMatrix();
     UploadCoordinateGridData();
}

void mywindow::PaintGL()
{
    //qDebug()<<isExposed();
    if (!isExposed()) {
       return;
     }
    qDebug()<<focus_distance_;

     context_->makeCurrent(this);

     glClearColor(bg_color_[0], bg_color_[1], bg_color_[2], 1.0f);
     glClear(GL_COLOR_BUFFER_BIT | GL_DEPTH_BUFFER_BIT);
     GLfloat mat_specular[] = { 1.0, 1.0, 1.0, 1.0 };  //镜面反射参数
     GLfloat mat_shininess[] = { 50.0 };               //高光指数
     GLfloat light_position[] = { 1.0, 1.0, 1.0, 0.0 };
     GLfloat white_light[] = { 1.0, 1.0, 1.0, 1.0 };   //灯位置(1,1,1), 最后1-开关
     GLfloat Light_Model_Ambient[] = { 0.2, 0.2, 0.2, 1.0 }; //环境光参数

//     glShadeModel(GL_SMOOTH);
//     glMaterialfv(GL_FRONT, GL_SPECULAR, mat_specular);
//             glMaterialfv(GL_FRONT, GL_SHININESS, mat_shininess);

//             //灯光设置
//             glLightfv(GL_LIGHT0, GL_POSITION, light_position);
//             glLightfv(GL_LIGHT0, GL_DIFFUSE, white_light);   //散射光属性
//             glLightfv(GL_LIGHT0, GL_SPECULAR, white_light);  //镜面反射光
//             glLightModelfv(GL_LIGHT_MODEL_AMBIENT, Light_Model_Ambient);  //环境光参数

//             glEnable(GL_LIGHTING);   //开关:使用光
//             glEnable(GL_LIGHT0);     //打开0#灯




     const QMatrix4x4 pmv_matrix = projection_matrix_ * model_view_matrix_;

     // Model view matrix for center of view
     QMatrix4x4 model_view_center_matrix = model_view_matrix_;
     //不加逆的话那个grid坐标 会很奇怪
     const Eigen::Vector4f rot_center =
         QMatrixToEigen(model_view_matrix_).inverse() *
         Eigen::Vector4f(0, 0, -focus_distance_, 1);//限制x,y移动，z随坐标变化，可同时改变z坐标轴有变化，网格没裱花

     QVector4D vec3(rot_center(0), rot_center(1),
                    rot_center(2),rot_center(3));

     //直接0，0，0，就不行

//printMatrix(model_view_center_matrix);
     model_view_center_matrix.translate(rot_center(0), rot_center(1),
                                        rot_center(2));//不然的话网格和坐标会重合
//printMatrix(model_view_center_matrix);
     const QMatrix4x4 pmvc_matrix = projection_matrix_ * model_view_center_matrix;


     // Coordinate system
     if (coordinate_grid_enabled_) {
       coordinate_axes_painter_.Render(pmv_matrix, width(), height(), 2);
       coordinate_grid_painter_.Render(pmvc_matrix, width(), height(), 1);
     }

     // Point cloud
     point_painter_.Render(pmv_matrix, point_size_);
     point_connection_painter_.Render(pmv_matrix, width(), height(), 1);

     // Images
//     image_line_painter_.Render(pmv_matrix, width(), height(), 1);
//     image_triangle_painter_.Render(pmv_matrix);
//     image_connection_painter_.Render(pmv_matrix, width(), height(), 1);

     // Movie grabber cameras
     //texture->bind();
     //movie_grabber_path_painter_.Render(pmv_matrix, width(), height(), 1.5);
     //movie_grabber_line_painter_.Render(pmv_matrix, width(), height(), 1);
     movie_grabber_triangle_painter_.Render(pmv_matrix);

     context_->swapBuffers(this);
}

void mywindow::initTextures()
{

    //texture = new QOpenGLTexture(QImage("C:/Users/zou/Desktop/openProject/Qtest/scene_dense_mesh_texture.png").mirrored());


//    if(texture != NULL)
//        qDebug("success image");
//    texture->setMinificationFilter(QOpenGLTexture::Nearest);


//    texture->setMagnificationFilter(QOpenGLTexture::Linear);

//       texture->setWrapMode(QOpenGLTexture::Repeat);

}

void mywindow::Upload()
{

    ComposeProjectionMatrix();
    UploadMeshData();
    PaintGL();
}

void mywindow::UploadMeshData()
{
     std::vector<TrianglePainter::Data> triangle_data_all;
     qDebug()<<"_Vertices.size()"<<_Vertices.size();
     for(int i =0;i<_Vertices.size();i++)
     {
         TrianglePainter::Data triangle;
         triangle.point1 = PointPainter::Data(_Points[_Vertices[i](0)](0)  , _Points[_Vertices[i](0)](1), _Points[_Vertices[i](0)](2),
                 _Points[_Vertices[i](0)](3),_Points[_Vertices[i](0)](4),_Points[_Vertices[i](0)](5), _Textures[i](0),_Textures[i](1));

         triangle.point2 = PointPainter::Data(_Points[_Vertices[i](1)](0)  , _Points[_Vertices[i](1)](1), _Points[_Vertices[i](1)](2),
                 _Points[_Vertices[i](1)](3),_Points[_Vertices[i](1)](4),_Points[_Vertices[i](1)](5), _Textures[i](2),_Textures[i](3));

         triangle.point3 = PointPainter::Data(_Points[_Vertices[i](2)](0)  , _Points[_Vertices[i](2)](1), _Points[_Vertices[i](2)](2),
                 _Points[_Vertices[i](2)](3),_Points[_Vertices[i](2)](4),_Points[_Vertices[i](2)](5), _Textures[i](4),_Textures[i](5));

         if(i==_Vertices.size()-1)
         {
             qDebug()<<"point coordinate"<<_Points[_Vertices[i](0)](0)  , _Points[_Vertices[i](0)](1), _Points[_Vertices[i](0)](2);
             qDebug()<<"list"<<_Vertices[i](0)<<" "<<_Vertices[i](1)
                                  <<" "<<_Vertices[i](2)<<" "<<_Textures[i](0)<<" "<<_Textures[i](1)<<_Textures[i](2)<<" "<<_Textures[i](3)
                                                                                                                       <<_Textures[i](4)<<" "<<_Textures[i](5);
         }

//         triangle.point2 = PointPainter::Data(_Points[_Vertices[i](1)](0)  , _Points[_Vertices[i](1)](1), _Points[_Vertices[i](1)](2), GRID_RGBA);
//         triangle.point3 = PointPainter::Data(_Points[_Vertices[i](2)](0)  , _Points[_Vertices[i](2)](1), _Points[_Vertices[i](2)](2), GRID_RGBA);
         triangle_data_all.push_back(triangle);


     }
     movie_grabber_triangle_painter_.Upload(triangle_data_all);


}



void mywindow::printMatrix(QMatrix4x4 matrix)
{
    int n =0;
    using namespace std;
    float* mat = new float[16];
    matrix.copyDataTo(mat);
    for(int i =0;i<16;i++)
    {

        std::cout <<mat[i]<<" ";
        n++;
        if(n>3)
        {
            std::cout<<std::endl;

            n=0;
        }

    }
    cout<<"====================="<<endl;
}

void mywindow::exposeEvent(QExposeEvent *event)
{
    Q_UNUSED(event);

    if (isExposed())
        PaintGL();
}

Eigen::Matrix4f mywindow::QMatrixToEigen(const QMatrix4x4 &matrix)
{
    Eigen::Matrix4f eigen;
      for (size_t r = 0; r < 4; ++r) {
        for (size_t c = 0; c < 4; ++c) {
          eigen(r, c) = matrix(r, c);
        }
      }
      //qDebug()<<eigen<<endl;
      return eigen;
}

void mywindow::InitializePainters()
{
    coordinate_axes_painter_.Setup();
    coordinate_grid_painter_.Setup();

    point_painter_.Setup();
    point_connection_painter_.Setup();

    image_line_painter_.Setup();
    image_triangle_painter_.Setup();
    image_connection_painter_.Setup();

    movie_grabber_path_painter_.Setup();
    movie_grabber_line_painter_.Setup();
    movie_grabber_triangle_painter_.Setup();
}

void mywindow::InitializeSettings()
{
    glEnable(GL_DEPTH_TEST);//启用深度测试 根据坐标的远近自动隐藏被遮住的图形（材料
    glEnable(GL_BLEND);//启用颜色混合。例如实现半透明效果
    glBlendFunc(GL_SRC_ALPHA, GL_ONE_MINUS_SRC_ALPHA);//表示把渲染的图像融合到目标区域。也就是说源的每一个像素的alpha都等于自己的alpha，
                               //目标的每一个像素的alpha等于1减去该位置源像素的alpha。 因此不论叠加多少次，亮度是不变的。

    glEnable(GL_VERTEX_PROGRAM_POINT_SIZE);//这样在Shader中可以访问glPointSize;
                         //如果启用，并且顶点着色器处于活动状态，则派生的点大小将从（可能被剪切的）着色器内置的gl_PointSize中获取，并被钳位到实现相关的点大小范围。
    glEnable(GL_TEXTURE_2D);


}

void mywindow::InitializeView()
{
      point_size_ = kInitPointSize;
      image_size_ = kInitImageSize;
      focus_distance_ = kInitFocusDistance;

      model_view_matrix_.setToIdentity();

      model_view_matrix_.translate(0, 0, -focus_distance_);

      model_view_matrix_.rotate(225, 1, 0, 0);
      model_view_matrix_.rotate(-45, 0, 1, 0);
}

void mywindow::mousePressEvent(QMouseEvent *event)
{
    if (mouse_press_timer_.isActive()) {  // Select objects (2. click)
        mouse_is_pressed_ = false;
        mouse_press_timer_.stop();
        selection_buffer_.clear();
        //SelectObject(event->pos().x(), event->pos().y());
      } else {  // Set timer to remember 1. click
        mouse_press_timer_.setSingleShot(true);
        mouse_press_timer_.start(kDoubleClickInterval);
        mouse_is_pressed_ = true;
        prev_mouse_pos_ = event->pos();
      }
    event->accept();
}

void mywindow::mouseReleaseEvent(QMouseEvent *event)
{
    mouse_is_pressed_ = false;
    event->accept();
}

void mywindow::mouseMoveEvent(QMouseEvent *event)
{
    if (mouse_is_pressed_) {
       if (event->buttons() & Qt::RightButton ||
           (event->buttons() & Qt::LeftButton &&
            event->modifiers() & Qt::ControlModifier)) {
         TranslateView(event->pos().x(), event->pos().y(), prev_mouse_pos_.x(),
                       prev_mouse_pos_.y());
       } else if (event->buttons() & Qt::LeftButton) {
         RotateView(event->pos().x(), event->pos().y(), prev_mouse_pos_.x(),
                    prev_mouse_pos_.y());
       }
     }
     prev_mouse_pos_ = event->pos();
     event->accept();
}

void mywindow::wheelEvent(QWheelEvent *event)
{
    if (event->modifiers() & Qt::ControlModifier) {
        ChangePointSize(event->delta());
      } else if (event->modifiers() & Qt::AltModifier) {
        ChangeCameraSize(event->delta());
      } else if (event->modifiers() & Qt::ShiftModifier) {
        ChangeNearPlane(event->delta());
      } else {
        ChangeFocusDistance(event->delta());
      }
    event->accept();
}

void mywindow::ChangeFocusDistance(const float delta)
{
    if (delta == 0.0f) {
        return;
      }
      const float prev_focus_distance = focus_distance_;
      float diff = delta * ZoomScale() * kFocusSpeed;
      focus_distance_ -= diff;
      if (focus_distance_ < kMinFocusDistance) {
        focus_distance_ = kMinFocusDistance;
        diff = prev_focus_distance - focus_distance_;
      } else if (focus_distance_ > kMaxFocusDistance) {
        focus_distance_ = kMaxFocusDistance;
        diff = prev_focus_distance - focus_distance_;
      }
      const Eigen::Matrix4f vm_mat = QMatrixToEigen(model_view_matrix_).inverse();
      const Eigen::Vector3f tvec(0, 0, diff);
      const Eigen::Vector3f tvec_rot = vm_mat.block<3, 3>(0, 0) * tvec;
      model_view_matrix_.translate(tvec_rot(0), tvec_rot(1), tvec_rot(2));
      ComposeProjectionMatrix();
      UploadCoordinateGridData();
      PaintGL();
}

void mywindow::ChangeNearPlane(const float delta)
{
    if (delta == 0.0f) {
        return;
      }
      near_plane_ *= (1.0f + delta / 100.0f * kNearPlaneScaleSpeed);
      near_plane_ = std::max(kMinNearPlane, std::min(kMaxNearPlane, near_plane_));
      ComposeProjectionMatrix();
      UploadCoordinateGridData();
      PaintGL();
}

void mywindow::ChangePointSize(const float delta)
{
    if (delta == 0.0f) {
        return;
      }
      point_size_ *= (1.0f + delta / 100.0f * kPointScaleSpeed);
      point_size_ = std::max(kMinPointSize, std::min(kMaxPointSize, point_size_));
      PaintGL();
}

void mywindow::ChangeCameraSize(const float delta)
{
    if (delta == 0.0f) {
        return;
      }
      image_size_ *= (1.0f + delta / 100.0f * kImageScaleSpeed);
      image_size_ = std::max(kMinImageSize, std::min(kMaxImageSize, image_size_));
//      UploadImageData();
//      UploadMovieGrabberData();
      PaintGL();
}

void mywindow::SelectObject(const int x, const int y)
{

}

Eigen::Vector3f mywindow::PositionToArcballVector(const float x, const float y) const
{
    Eigen::Vector3f vec(2.0f * x / width() - 1, 1 - 2.0f * y / height(), 0.0f);
      const float norm2 = vec.squaredNorm();
      if (norm2 <= 1.0f) {
        vec.z() = std::sqrt(1.0f - norm2);
      } else {
        vec = vec.normalized();
      }
      return vec;

}

void mywindow::RotateView(const float x, const float y, const float prev_x, const float prev_y)
{
    if (x - prev_x == 0 && y - prev_y == 0) {
        return;
      }

      // Rotation according to the Arcball method "ARCBALL: A User Interface for
      // Specifying Three-Dimensional Orientation Using a Mouse", Ken Shoemake,
      // University of Pennsylvania, 1992.

      // Determine Arcball vector on unit sphere.
      const Eigen::Vector3f u = PositionToArcballVector(x, y);
      const Eigen::Vector3f v = PositionToArcballVector(prev_x, prev_y);

      // Angle between vectors.
      const float angle = 2.0f * std::acos(std::min(1.0f, u.dot(v)));

      const float kMinAngle = 1e-3f;
      if (angle > kMinAngle) {
        const Eigen::Matrix4f vm_mat = QMatrixToEigen(model_view_matrix_).inverse();

        // Rotation axis.
        Eigen::Vector3f axis = vm_mat.block<3, 3>(0, 0) * v.cross(u);
        axis = axis.normalized();
        // Center of rotation is current focus.
        const Eigen::Vector4f rot_center =
            vm_mat * Eigen::Vector4f(0, 0, -focus_distance_, 1);
        // First shift to rotation center, then rotate and shift back.
        model_view_matrix_.translate(rot_center(0), rot_center(1), rot_center(2));
        model_view_matrix_.rotate(angle*57.3, axis(0), axis(1), axis(2));
        model_view_matrix_.translate(-rot_center(0), -rot_center(1),
                                     -rot_center(2));
        PaintGL();
        }
}

void mywindow::TranslateView(const float x, const float y, const float prev_x, const float prev_y)
{
    if (x - prev_x == 0 && y - prev_y == 0) {
        return;
      }

      Eigen::Vector3f tvec(x - prev_x, prev_y - y, 0.0f);

//      if (options_->render->projection_type ==
//          RenderOptions::ProjectionType::PERSPECTIVE) {
        tvec *= ZoomScale();
//      } else if (options_->render->projection_type ==
//                 RenderOptions::ProjectionType::ORTHOGRAPHIC) {
//        tvec *= 2.0f * OrthographicWindowExtent() / height();
//      }

      const Eigen::Matrix4f vm_mat = QMatrixToEigen(model_view_matrix_).inverse();

      const Eigen::Vector3f tvec_rot = vm_mat.block<3, 3>(0, 0) * tvec;
      model_view_matrix_.translate(tvec_rot(0), tvec_rot(1), tvec_rot(2));

      PaintGL();
}

void mywindow::UploadCoordinateGridData()
{
    const float scale = ZoomScale();
    qDebug()<<scale;

     // View center grid
     std::vector<LinePainter::Data> grid_data(3);

     grid_data[0].point1 = PointPainter::Data(-20 * scale, 0, 0, GRID_RGBA);
     grid_data[0].point2 = PointPainter::Data(20 * scale, 0, 0, GRID_RGBA);

     grid_data[1].point1 = PointPainter::Data(0, -20 * scale, 0, GRID_RGBA);
     grid_data[1].point2 = PointPainter::Data(0, 20 * scale, 0, GRID_RGBA);

     grid_data[2].point1 = PointPainter::Data(0, 0, -20 * scale, GRID_RGBA);
     grid_data[2].point2 = PointPainter::Data(0, 0, 20 * scale, GRID_RGBA);

     coordinate_grid_painter_.Upload(grid_data);

     // Coordinate axes
     std::vector<LinePainter::Data> axes_data(3);

     axes_data[0].point1 = PointPainter::Data(0, 0, 0, X_AXIS_RGBA);
     axes_data[0].point2 = PointPainter::Data(50 * scale, 0, 0, X_AXIS_RGBA);

     axes_data[1].point1 = PointPainter::Data(0, 0, 0, Y_AXIS_RGBA);
     axes_data[1].point2 = PointPainter::Data(0, 50 * scale, 0, Y_AXIS_RGBA);

     axes_data[2].point1 = PointPainter::Data(0, 0, 0, Z_AXIS_RGBA);
     axes_data[2].point2 = PointPainter::Data(0, 0, 50 * scale, Z_AXIS_RGBA);

     coordinate_axes_painter_.Upload(axes_data);
}






void mywindow::UploadImageData(const bool selection_mode)
{
//    std::vector<LinePainter::Data> line_data;
//      line_data.reserve(8 * reg_image_ids.size());

//      std::vector<TrianglePainter::Data> triangle_data;
//      triangle_data.reserve(2 * reg_image_ids.size());

}

void mywindow::ComposeProjectionMatrix()
{
    projection_matrix_.setToIdentity();
//      if (options_->render->projection_type ==
//          RenderOptions::ProjectionType::PERSPECTIVE) {
        projection_matrix_.perspective(kFieldOfView, AspectRatio(), near_plane_,
                                       kFarPlane);
//      } else if (options_->render->projection_type ==
//                 RenderOptions::ProjectionType::ORTHOGRAPHIC) {
//        const float extent = OrthographicWindowExtent();
//        projection_matrix_.ortho(-AspectRatio() * extent, AspectRatio() * extent,
//                                 -extent, extent, near_plane_, kFarPlane);
      //}
        //}
}

float mywindow::ZoomScale() const
{
    return 2.0f * std::tan(static_cast<float>(kFieldOfView*0.017) / 2.0f) *
            std::abs(focus_distance_) / height();
}

float mywindow::AspectRatio() const
{
    return static_cast<float>(width()) / static_cast<float>(height());
}


